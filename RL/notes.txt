carla setup:
https://www.youtube.com/playlist?list=PLQVvvaa0QuDeI12McNQdnTlWz9XlCa0uo

geohot - an architecture for life [https://geohot.github.io/blog/jekyll/update/2021/10/29/an-architecture-for-life.html]:
- freeze the weights of the representation, then train dynamics and prediction in a simulator
- temperature parameter = 0. Nobody would be happy if their car “explored”, it should only “exploit”

behavioral cloning [https://www.andrew.cmu.edu/course/10-403/slides/S19_lecture2_behaviorcloning.pdf]

lecture - reinforcement-intro.pdf:
- use policy gradient (43) => loss = log(π) * A (where A is the reward)

lecture - practical_deep_RL.pdf:
- policy gradients for trajectories (14)

general:
- observation (o) comes from CNN latent space + desire => state (s)
- Q value comes from RNN latent space
- action (a) comes from policy network (π)
- a = steering wheel angle or trajectory (?)

